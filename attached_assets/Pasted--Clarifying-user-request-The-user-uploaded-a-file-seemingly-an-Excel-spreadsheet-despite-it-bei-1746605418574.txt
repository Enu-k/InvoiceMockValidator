**Clarifying user request**

The user uploaded a file, seemingly an Excel spreadsheet despite it being named a CSV. The first sheet, "Invoice Request Schema," outlines required fields for their AP software, Kodo, detailing which fields are OCR-compatible and which require more complex automation. The next 10 sheets, titled "Invoice Request Samples," contain mock invoices with sample data. I’ll double-check the file format to make sure I'm interpreting everything correctly and proceed with the task!

**Creating a plan for an AI agent**

The task is to create an AI agent that processes invoices using OCR and validates fields with backend data. To do this, I need to analyze the uploaded file, which might be an Excel document misnamed as CSV. The plan involves using a tool to inspect the file structure (since file\_search isn't available, I may need to rely on Python for reading CSV or parsing its content). Then, I’ll outline a step-by-step approach to set up the AI agent and document the required steps for the user.

**Analyzing the file**

The user provided a specific path to the uploaded CSV file. Since I can use Python for analysis, I’ll open the file to figure out the field names and structure. I'll start by parsing the first 20 rows to get a clearer picture of the data. This will help me understand how to proceed with processing and creating the AI agent’s workflow. I'll go ahead and get started on this task.


**Reading the file**

I noticed that I can use Python to access the file at the provided location and open it for analysis. The next step is to focus on understanding the field names. I’ll start by parsing the first 20 rows to examine the structure, and based on what I find, I might read more lines if needed. That will give me a clearer idea of how to proceed with processing this file effectively. Let's go ahead and dive into the content!


**Reassessing file format**

I’m starting to think the file might be mis-specified. If it’s originally an Excel file, its extension should be '.xls', but this one is marked as CSV. It's possible that the content has multiple data sheets, with blank lines separating each. To figure this out, I'll examine the file more closely, especially after line 90. That should give me a better idea of how the data is organized and how to process it. Let’s take a look!

**Inspecting the CSV file**

The user mentioned multiple sheets in the file, but it seems like there are only 178 lines, so maybe it's just the first sheet. I’ll start by analyzing the first 20 rows to better understand the layout. There's a chance the user combined sheets into one file using different headers, so I’ll look for “Invoice Request Samples” within it, just in case they intended to reference other sections that might not be included. Let's dive into this.


**Examining the file structure**

The file might actually be mis-specified — it could be an Excel file mistakenly named as a CSV. The content might be multi-line, representing different sheets separated by blank lines. After reviewing up to line 90, I suspect it remains just the first sheet. In any case, let's move forward by parsing the file into a dataframe. This will help me list the field names and their attributes, which will inform the plan for the AI agent. Let’s get this organized!


**Creating an AI agent plan**

The file might be mis-specified — it could be an Excel file labeled as CSV, with content spanning multiple sheets separated by blank lines. I'll review the first few lines to verify, but the file might mainly be from the first sheet. Regardless, I can still use the data to form a plan for the AI agent. By parsing the file into a dataframe, I'll list the fields and attributes. Once that’s done, I’ll create a step-by-step plan to set up the AI agent in the next hour!

**Creating an AI Agent Plan**

The plan will need to cover various aspects including tool and tech stack choices, architecture for OCR using Veryfi, and setting up an AI agent (likely with a framework like LangChain). I'll also include a to-do list — tasks like environment setup, obtaining API keys, creating a mapping, building validation calls, and handling any ambiguous fields. Plus, I’ll look into creating a UI. I'll also focus on providing clear documentation and a step-by-step timeline for achieving all this in one hour. First, I’ll gather details from Veryfi documentation. Let's check for the up-to-date docs!


**Creating the AI Agent Plan**

The plan will cover things like choosing tools and tech stacks, architecture for OCR with Veryfi, and setting up the AI Agent (likely using a framework like LangChain). There will be a to-do list with tasks such as environment setup, obtaining API keys, and creating transformation mappings. The plan will also focus on backend integrations and validation logic. I'll need to quickly gather and refer to Veryfi docs for relevant endpoints, provide sample code, and incorporate custom validation, like fuzzy matching for company names.

**Building the AI Agent Plan**

The plan includes clear tasks to achieve the goal within one hour:

1. Set up environment and gather credentials (Veryfi API keys, Kodo backend).
2. Develop a pipeline to handle invoice PDFs: process via Veryfi, parse JSON, map fields.
3. Implement validation: fuzzy score matching, AI classification, and automation flows for handling new company records.
4. Finalize into a LangChain orchestrator, test on sample invoices, and deploy the system with monitoring.

This structured approach will help ensure we complete all steps in time while logging progress effectively.

**Building the Plan**

I think we can include a simple table summarizing field categories. I'll include sample code snippets for calls to help illustrate things. Also, I'll draft a guide for extending or hardening the system post-hour.

We’ll make sure to reference the Veryfi docs for citations and include steps for supervising AI classification. Plus, I'll look at the uploaded file and categorize fields that require validation, counting fields that are marked for validation.


---

I think a simple table summarizing field categories would be helpful, alongside sample code snippets to guide implementation. I'll include a guide for extending or hardening the system post-hour. I also need to make sure to reference the Veryfi docs, and incorporate AI classification for supervision. It looks like I'll need to extract a list of fields needing validation from the uploaded file, categorize them, and compute counts for fields where validation includes 'Selected from Master.' Then, I'll list those fields.


Thought for 1m 48s


### Goal

Stand up an **invoice-processing AI Agent** that, within one hour, can:

1. **Ingest a PDF/image invoice** → call **Veryfi OCR** → receive raw JSON.
2. **Map OCR fields → Kodo “Invoice Request” schema** (see uploaded sheet).
3. **Validate / enrich** fields that require a lookup against Kodo master data (company, vendor, etc.) via internal APIs.
4. **Return a ready-to-submit JSON payload** or surface clear exceptions for human review.

---

## 0. Prerequisites (do these before the clock starts)

| Asset                                                      | Where to get it                | Notes                                                                                         |
| ---------------------------------------------------------- | ------------------------------ | --------------------------------------------------------------------------------------------- |
| Veryfi `CLIENT_ID`, `USERNAME`, `API_KEY`, `CLIENT_SECRET` | Veryfi dashboard (10-sec copy) | 14-day free tier is fine.                                                                     |
| Kodo API base URL + auth token                             | Internal                       | Must expose search endpoints for **Company**, **Department**, **Sub-department**, **Vendor**. |
| Python 3.11 + `pipx`                                       | Local / server                 | Use virtual-env to keep clean.                                                                |
| Sample invoices (10)                                       | In the file you uploaded       | Will act as test harness.                                                                     |

---

## 1-Hour Build Plan (minute-by-minute)

| Time      | Action                                                                                                                                                                                                                                                                                                                                              | Output                                  |
| --------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------- |
| 00-05 min | `python -m venv env && source env/bin/activate`<br>`pip install requests pydantic rapidfuzz langchain-openai python-dotenv`                                                                                                                                                                                                                         | Clean env                               |
| 05-10 min | Drop `.env` with Veryfi & Kodo creds.                                                                                                                                                                                                                                                                                                               | Secrets file                            |
| 10-20 min | **Module A – OCR Tool**  (`veryfi_tool.py`)<br>﻿• POST `/v8/partner/documents` with file bytes <br>﻿• Return raw JSON.                                                                                                                                                                                                                              | Re-usable wrapper                       |
| 20-35 min | **Module B – Field Mapper** (`mapper.py`)<br>﻿• Load uploaded “Invoice Request Schema” into dict (<span style="font-size:90%">already parsed</span>).<br>﻿• Create map `{veryfi_key: kodo_field}`.<br>﻿• Mark fields in four buckets:  **Direct**, **Master-Lookup**, **AI-Categorise**, **Manual**.                                                | Mapping dict & bucket tags              |
| 35-45 min | **Module C – Master-Data Validator** (`master_lookup.py`)<br>﻿• Generic `search(entity, term)` hitting Kodo API.<br>﻿• Use `rapidfuzz.process.extractOne` (≥ 85 score) to pick best match.<br>﻿• If no confident hit → raise `NeedsReview`.                                                                                                         | Fuzzy-matching validator                |
| 45-55 min | **Module D – Agent Orchestrator** (`agent.py`)<br>﻿• Build LangChain **Structured Tool** wrappers:<br>    `OCRTool`, `MasterLookupTool`, `AICategoriser` (OpenAI function call).<br>﻿• Define prompt: “Given OCR JSON + mapping + examples, return valid Kodo payload or raise NeedsReview list.”<br>﻿• Run on 1-2 sample invoices, assert success. | CLI script `python agent.py sample.pdf` |
| 55-60 min | **Smoke test all 10 samples**.<br>Log success / failures to `results.csv`.                                                                                                                                                                                                                                                                          | Proof of life ✅                         |

> **Elapsed:** 60 minutes — ready for pilot ingestion.

---

## 2. Detailed TODO Check-List

### A. Code skeleton

```
src/
 ├─ config.py          # loads .env
 ├─ veryfi_tool.py     # OCR API wrapper
 ├─ mapper.py          # maps & buckets fields
 ├─ master_lookup.py   # generic search wrapper
 ├─ ai_tools.py        # OpenAI categoriser (department, GL code …)
 └─ agent.py           # LangChain agent orchestration
```

### B. Field buckets (excerpt)

| Kodo Field                                                       | Capture                   | Handling                                                                       |
| ---------------------------------------------------------------- | ------------------------- | ------------------------------------------------------------------------------ |
| **Invoice Number, Invoice Date, GSTIN, Qty, Rate**               | Veryfi JSON keys          | **Direct** – trust OCR.                                                        |
| **Company Name, Vendor Name / Code, Department, Sub-department** | OCR → `MasterLookupTool`  | **Master-Lookup** – fuzzy match against Kodo API; if score < 85 → NeedsReview. |
| **Account Head, Bill-to Location, Ship-to Location**             | Not present or unreliable | **AI-Categorise / Manual** – ask OpenAI using internal taxonomy, else flag.    |

*(Buckets derived from sheet analysis.)*

### C. Veryfi API call (sample)

```python
def process_invoice(path: str) -> dict:
    url = "https://api.veryfi.com/v8/partner/documents"
    headers = {
        "CLIENT-ID": os.getenv("VERYFI_CLIENT_ID"),
        "AUTHORIZATION": os.getenv("VERYFI_API_KEY"),
        "ACCEPT": "application/json"
    }
    with open(path, "rb") as f:
        resp = requests.post(url, files={"file": f}, headers=headers)
    resp.raise_for_status()
    return resp.json()
```

Veryfi responds in <3 s with 150-plus keyed fields ([veryfi.com][1], [docs.veryfi.com][2]).

### D. Master-data search

```python
def kodo_search(entity: str, query: str) -> str|None:
    r = requests.get(
        f"{os.getenv('KODO_URL')}/search/{entity}",
        params={"q": query},
        headers={"Authorization": f"Bearer {os.getenv('KODO_TOKEN')}"}
    )
    hits = r.json()  # [{"name": "...", "id": "..."}]
    match, score = rapidfuzz.process.extractOne(
        query, [h["name"] for h in hits]
    )
    return match if score >= 85 else None
```

### E. Agent prompt snippet

```
You are Kodo-Invoice-Agent⚡. 
Input: {ocr_json}
Task:
 1. Map each field using {mapping_dict}.
 2. Call MasterLookupTool for any field tagged MASTER.
 3. Call AICategoriser for any field tagged AI.
Output JSON:
 {
   "payload": { ...Kodo schema... },
   "needs_review": [<field list>]
 }
```

### F. Deployment & secrets

```bash
docker build -t kodo-agent .
docker run -e VERYFI_CLIENT_ID=... -e KODO_TOKEN=... kodo-agent
```

*Add Datadog / Sentry for error tracking; pipe needs-review items to Slack.*

---

## 3. Guide: Running It

1. **Activate env**
   `source env/bin/activate`

2. **Process invoices**
   `python agent.py ./samples/invoice1.pdf`

3. **Check output**—successful runs write `payload.json`; failures append to `needs_review.csv` with the fuzzy-match suggestions.

---

## 4. After the 1-Hour MVP

* **Add line-item validation**: cross-check SKU & HSN code against Rate-Card master.
* **Queue new-vendor onboarding**: if Vendor not found, auto-draft “Add Vendor” request.
* **Cache master data** locally (Redis) for zero-latency lookup.
* **Convert CLI to AWS Lambda** behind API Gateway; trigger via S3 upload event.
* **Add guardrail metrics**: extraction accuracy, auto-approval rate, mean review time.

---

### You’re set!

Follow the timeline, copy the snippets, and you’ll have a functional invoice-processing AI Agent capturing, validating, and enriching invoices inside **60 minutes**.

[1]: https://www.veryfi.com/invoice-ocr-api/ "Invoices OCR API - Veryfi"
[2]: https://docs.veryfi.com/api/receipts-invoices/process-a-document/ "Process a Document | Veryfi Docs: API Reference, Tutorials, and ..."
